{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    " \n",
    "# 学习使用 tf.app.flags 使用，全局变量\n",
    "# 可以再命令行中运行也是比较方便，如果只写 python app_flags.py 则代码运行时默认程序里面设置的默认设置\n",
    "# 若 python app_flags.py --train_data_path <绝对路径 train.txt> --max_sentence_len 100\n",
    "#    --embedding_size 100 --learning_rate 0.05  代码再执行的时候将会按照上面的参数来运行程序\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "FLAGS = tf.app.flags.FLAGS\n",
    " \n",
    "# tf.app.flags.DEFINE_string(\"param_name\", \"default_val\", \"description\")\n",
    "tf.app.flags.DEFINE_string(\"train_data_path\", \"/home/yongcai/chinese_fenci/train.txt\", \"training data dir\")\n",
    "tf.app.flags.DEFINE_string(\"log_dir\", \"./logs\", \" the log dir\")\n",
    "tf.app.flags.DEFINE_integer(\"max_sentence_len\", 80, \"max num of tokens per query\")\n",
    "tf.app.flags.DEFINE_integer(\"embedding_size\", 50, \"embedding size\")\n",
    " \n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 0.001, \"learning rate\")\n",
    " \n",
    " \n",
    "def main(unused_argv):\n",
    "    train_data_path = FLAGS.train_data_path\n",
    "    print(\"train_data_path\", train_data_path)\n",
    "    max_sentence_len = FLAGS.max_sentence_len\n",
    "    print(\"max_sentence_len\", max_sentence_len)\n",
    "    embdeeing_size = FLAGS.embedding_size\n",
    "    print(\"embedding_size\", embdeeing_size)\n",
    "    abc = tf.add(max_sentence_len, embdeeing_size)\n",
    " \n",
    "    init = tf.global_variables_initializer()\n",
    " \n",
    "    #with tf.Session() as sess:\n",
    "        #sess.run(init)\n",
    "        #print(\"abc\", sess.run(abc))\n",
    " \n",
    "    sv = tf.train.Supervisor(logdir=FLAGS.log_dir, init_op=init)\n",
    "    with sv.managed_session() as sess:\n",
    "        print(\"abc:\", sess.run(abc))\n",
    " \n",
    "        # sv.saver.save(sess, \"/home/yongcai/tmp/\")\n",
    " \n",
    " \n",
    "# 使用这种方式保证了，如果此文件被其他文件 import的时候，不会执行main 函数\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()   # 解析命令行参数，调用main 函数 main(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用方法：\n",
    "python app_flags.py --train_data_path <绝对路径 train.txt> --max_sentence_len 100 --embedding_size 100 --learning_rate 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
