{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5488135   0.71518937]\n",
      " [ 0.60276338  0.54488318]\n",
      " [ 0.4236548   0.64589411]\n",
      " [ 0.43758721  0.891773  ]\n",
      " [ 0.96366276  0.38344152]\n",
      " [ 0.79172504  0.52889492]\n",
      " [ 0.56804456  0.92559664]\n",
      " [ 0.07103606  0.0871293 ]\n",
      " [ 0.0202184   0.83261985]\n",
      " [ 0.77815675  0.87001215]\n",
      " [ 0.97861834  0.79915856]]\n",
      "-----------------------------\n",
      "[[ 0.60276338  0.54488318]\n",
      " [ 0.5488135   0.71518937]\n",
      " [ 0.4236548   0.64589411]\n",
      " [ 0.43758721  0.891773  ]]\n",
      "*****************************\n",
      "[[ 0.56804456  0.92559664]\n",
      " [ 0.07103606  0.0871293 ]\n",
      " [ 0.0202184   0.83261985]\n",
      " [ 0.96366276  0.38344152]]\n",
      "*****************************\n",
      "[[ 0.77815675  0.87001215]\n",
      " [ 0.97861834  0.79915856]\n",
      " [ 0.79172504  0.52889492]]\n",
      "[[ 0.4236548   0.64589411]\n",
      " [ 0.43758721  0.891773  ]\n",
      " [ 0.5488135   0.71518937]\n",
      " [ 0.96366276  0.38344152]]\n",
      "[[ 0.56804456  0.92559664]\n",
      " [ 0.79172504  0.52889492]\n",
      " [ 0.07103606  0.0871293 ]\n",
      " [ 0.77815675  0.87001215]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "x = np.random.sample((11, 2))\n",
    "print (x)\n",
    "print (\"-----------------------------\")\n",
    "\n",
    "\n",
    "# making a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset = dataset.shuffle(3)\n",
    "dataset = dataset.batch(4)\n",
    "dataset = dataset.repeat(2)\n",
    "\n",
    "# creating the iterator\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    parser = \"*****************************\"\n",
    "    print (sess.run(el))\n",
    "    print (parser)\n",
    "    print (sess.run(el))\n",
    "    print (parser)\n",
    "    print (sess.run(el))\n",
    "    print (sess.run(el))\n",
    "    print (sess.run(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 源数据集\n",
    "[[ 0.5488135   0.71518937]\n",
    " [ 0.60276338  0.54488318]\n",
    " [ 0.4236548   0.64589411]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.96366276  0.38344152]\n",
    " [ 0.79172504  0.52889492]\n",
    " [ 0.56804456  0.92559664]\n",
    " [ 0.07103606  0.0871293 ]\n",
    " [ 0.0202184   0.83261985]\n",
    " [ 0.77815675  0.87001215]\n",
    " [ 0.97861834  0.79915856]]\n",
    "\n",
    "#### 通过shuffle batch后取得的样本\n",
    "[[ 0.4236548   0.64589411]\n",
    " [ 0.60276338  0.54488318]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.5488135   0.71518937]]\n",
    "[[ 0.96366276  0.38344152]\n",
    " [ 0.56804456  0.92559664]\n",
    " [ 0.0202184   0.83261985]\n",
    " [ 0.79172504  0.52889492]]\n",
    "[[ 0.07103606  0.0871293 ]\n",
    " [ 0.97861834  0.79915856]\n",
    " [ 0.77815675  0.87001215]]  #最后一个batch样本个数为3\n",
    "[[ 0.60276338  0.54488318]\n",
    " [ 0.5488135   0.71518937]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.79172504  0.52889492]]\n",
    "[[ 0.4236548   0.64589411]\n",
    " [ 0.56804456  0.92559664]\n",
    " [ 0.0202184   0.83261985]\n",
    " [ 0.07103606  0.0871293 ]]\n",
    "[[ 0.77815675  0.87001215]\n",
    " [ 0.96366276  0.38344152]\n",
    " [ 0.97861834  0.79915856]] #最后一个batch样本个数为3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意如果repeat在shuffle之前使用： \n",
    "官方说repeat在shuffle之前使用能提高性能，但模糊了数据样本的epoch关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "x = np.random.sample((11,2))\n",
    "# make a dataset from a numpy array\n",
    "print(x)\n",
    "print()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset = dataset.repeat(2)\n",
    "dataset = dataset.shuffle(11)\n",
    "dataset = dataset.batch(4)\n",
    "\n",
    "# create the iterator\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[ 0.5488135   0.71518937]\n",
    " [ 0.60276338  0.54488318]\n",
    " [ 0.4236548   0.64589411]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.96366276  0.38344152]\n",
    " [ 0.79172504  0.52889492]\n",
    " [ 0.56804456  0.92559664]\n",
    " [ 0.07103606  0.0871293 ]\n",
    " [ 0.0202184   0.83261985]\n",
    " [ 0.77815675  0.87001215]\n",
    " [ 0.97861834  0.79915856]]\n",
    "\n",
    "[[ 0.56804456  0.92559664]\n",
    " [ 0.5488135   0.71518937]\n",
    " [ 0.60276338  0.54488318]\n",
    " [ 0.07103606  0.0871293 ]]\n",
    "[[ 0.96366276  0.38344152]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.43758721  0.891773  ]\n",
    " [ 0.77815675  0.87001215]]\n",
    "[[ 0.79172504  0.52889492]   #出现相同样本出现在同一个batch中\n",
    " [ 0.79172504  0.52889492]\n",
    " [ 0.60276338  0.54488318]\n",
    " [ 0.4236548   0.64589411]]\n",
    "[[ 0.07103606  0.0871293 ]\n",
    " [ 0.4236548   0.64589411]\n",
    " [ 0.96366276  0.38344152]\n",
    " [ 0.5488135   0.71518937]]\n",
    "[[ 0.97861834  0.79915856]\n",
    " [ 0.0202184   0.83261985]\n",
    " [ 0.77815675  0.87001215]\n",
    " [ 0.56804456  0.92559664]]\n",
    "[[ 0.0202184   0.83261985]\n",
    " [ 0.97861834  0.79915856]]          #可以看到最后个batch为2，而前面都是4  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用案例：\n",
    "def input_fn(filenames, batch_size=32, num_epochs=1, perform_shuffle=False):\n",
    "    print('Parsing', filenames)\n",
    "    def decode_libsvm(line):\n",
    "        #columns = tf.decode_csv(value, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "        #features = dict(zip(CSV_COLUMNS, columns))\n",
    "        #labels = features.pop(LABEL_COLUMN)\n",
    "        columns = tf.string_split([line], ' ')\n",
    "        labels = tf.string_to_number(columns.values[0], out_type=tf.float32)\n",
    "        splits = tf.string_split(columns.values[1:], ':')\n",
    "        id_vals = tf.reshape(splits.values,splits.dense_shape)\n",
    "        feat_ids, feat_vals = tf.split(id_vals,num_or_size_splits=2,axis=1)\n",
    "        feat_ids = tf.string_to_number(feat_ids, out_type=tf.int32)\n",
    "        feat_vals = tf.string_to_number(feat_vals, out_type=tf.float32)\n",
    "        #feat_ids = tf.reshape(feat_ids,shape=[-1,FLAGS.field_size])\n",
    "        #for i in range(splits.dense_shape.eval()[0]):\n",
    "        #    feat_ids.append(tf.string_to_number(splits.values[2*i], out_type=tf.int32))\n",
    "        #    feat_vals.append(tf.string_to_number(splits.values[2*i+1]))\n",
    "        #return tf.reshape(feat_ids,shape=[-1,field_size]), tf.reshape(feat_vals,shape=[-1,field_size]), labels\n",
    "        return {\"feat_ids\": feat_ids, \"feat_vals\": feat_vals}, labels\n",
    "\n",
    "    # Extract lines from input files using the Dataset API, can pass one filename or filename list\n",
    "    dataset = tf.data.TextLineDataset(filenames).map(decode_libsvm, num_parallel_calls=10).prefetch(500000)    # multi-thread pre-process then prefetch\n",
    "\n",
    "    # Randomizes input using a window of 256 elements (read into memory)\n",
    "    if perform_shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size) # Batch size to use\n",
    "\n",
    "    #return dataset.make_one_shot_iterator()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    #return tf.reshape(batch_ids,shape=[-1,field_size]), tf.reshape(batch_vals,shape=[-1,field_size]), batch_labels\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
